---
title: "Bacterial genome assembly and annotation supplemental"
author: "Matthew R. Gemmell"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
favicon: figures/NEOF_favicon.png
description: NEOF supplemental book for the Bacterial genome assembly and annotation workshop
cover-image: "figures/NEOF.png"
---
```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```

```{r cite-packages, include = FALSE}
# automatically create a bib database for R packages
# add any packages you want to cite here
knitr::write_bib(c(
  .packages(), 'bookdown', 'webexercises'
), 'packages.bib')
```

```{r, fig.align = 'center',out.width= '30%', echo=FALSE }
knitr::include_graphics(path = "figures/NEOF.png", auto_pdf = TRUE)
```

# Supplemental

```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/bact_genome_supplement.png", auto_pdf = TRUE)
```

This bookdown is a supplement to the main one. It contains some workflows and tools that are not part of the standard workflow. However, they may prove useful depending on your needs.

The sections in this supplement will cover:

- [Running the standard workflow with multiple samples](#multisampleworkflow)
- [Having too much sequencing coverage](#coverage)
- [Using long and short reads in hybrid assembly approaches](#hybrid)

Commands are in the following font, colour, and box.They should be run in the command line.

```{bash eval=FALSE}
echo "This is a command example" 
```

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.

<!--chapter:end:01-Bacterial_genome_supplemental.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Multiple sample workflow {#multisampleworkflow}
```{r, fig.align = 'center',out.width= '20%', echo=FALSE}
knitr::include_graphics(path = "figures/bacteria_multiple.png", auto_pdf = TRUE)
``` 

In the standard workflow bookdown we assembled and annotated a single sample/genome. In your future projects you will most likely need to carry this out for multiple samples at one. This could be carried out by running each command for each sample separately. However, there are much quicker methods.

In this section I will introduce you to my preferred method of carrying out commands on multiple samples. This involves a text file containing all the samples names in conjunction with `while read` loops.

## Multiple sample raw data
```{r, fig.align = 'center',out.width= '10%', echo=FALSE}
knitr::include_graphics(path = "figures/usb_stick.png", auto_pdf = TRUE)
``` 

Prior to running we need the data first. Copy over the directory that contains the data. The copied directory will be used as the analysis directory.

```{bash eval=FALSE}
#Move to your bacterial_assembly directory
cd ~/bacterial_assembly/
#Create a multi_sample_workflow directory with a data subdirectory
mkdir -p multi_sample_workflow/data
#Move into the new analysis directory
cd multi_sample_workflow
```

We will be running three _Bacillus cereus_ samples through the standard workflow. We'll create softlinks of the PacBio fastq files. It is always good to use softlinks for read data if you are not going to move it from its original location.

```{bash eval=FALSE}
#Softlink the PacBio fastq files we will use
ln -s /pub39/tea/nsc006/NEOF/bact_assembly/multi_sample_workflow/* data/
#List contents of the data directory
ls data
```

__Note__ When creating a softlink you should always use absolute (whole) paths for the original file/s you specify.

## Sample file
```{r, fig.align = 'center',out.width= '10%', echo=FALSE }
knitr::include_graphics(path = "figures/shopping_list.png", auto_pdf = TRUE)
``` 

Now it is time to make the sample file we will use for the future `while read` loops. This file will contain the sample names, one sample name per line.

For ease and convenience we will change the prefix of our PacBio fastq files to that of our desired samples names. In this case it is removing the `_0001` part.

We could rename all the files with the `mv` command but this might be awkward with many files. Instead we will use the `rename` command

```{bash eval=FALSE}
#Move into the data directory
cd data
#Rename the files
rename "s/_0001//" *.fastq
#List contents
ls .
```

`rename` will rename all indicated files (`*.fastq` = all files in current directory with the suffix `.fastq`) using syntax similar to the `sed` command. 

The `"s/_0001//"` is made of four parts:

1. `s/`: The `s` indicates we are carrying out a __substitution__. We will substitute regular expressions (i.e. pattern) for a replacement.
2. `/_0001/`: The first instance of `_0001` is to be substituted.
   - This is the regular expression.
3. `//`: The matched pattern (`_0001`) is to be substituted with nothing.
   - This is the replacement.
4. The end, after the last `/`: Contains any flags to be provided to the substitution command. 
   - The most commonly used flag is `g` which stands for global substitution. This will cause substitutions to occur for every instance of the regular expression found. Default is only the first instance of the regular expression to replaced.

For more info on `sed` please the Intro to Unix bookdown.

With our newly named softlinks we can quickly create our sample file.

```{bash eval=FALSE}
#List fastq files
ls *fastq
#List fastq files and remove the suffix (i.e. list sample names)
ls *fastq | sed "s/.fastq//"
#Redirect sample names to a new sample file
ls *fastq | sed "s/.fastq//" > ../samples.txt
```

Move up one directory to the main analysis directory and view the contents of the sample file.

```{bash eval=FALSE}
#Move up one directory
cd ..
#Print samples.txt contents to screen
cat samples.txt
```

## Start looping
```{r, fig.align = 'center',out.width= '10%', echo=FALSE }
knitr::include_graphics(path = "figures/while_loop.png", auto_pdf = TRUE)
``` 

Now that we have our data and our sample file we can start carrying out the standard workflow with loops.

Run the below example `while read` loop to see its output.

```{bash eval=FALSE}
cat samples.txt | while read s ; do echo "File for sample ${s} is ${s}.fastq" ; done
```

Ensure you are in a terminal with an active [`bacterial_assembly`](http://www.cgr.liv.ac.uk/illum/NEOFworkshops_5bfa93ca0482d69d/Bacterial_genome_assembly/Standard_workflow/05-Assembly.html#redbeanassemblyconda) environment then create an assembly output directory.

```{bash eval=FALSE}
mkdir redbean_assembly
```

Now to run the redbean assembly steps with loops

```{bash eval=FALSE}
#wtdbg2 step
cat samples.txt | while read s
do
wtdbg2 \
-x rs \
-g 5.4m \
-i data/${s}.fastq \
-o redbean_assembly/${s} \
-t 8
done
#Derive consensus
cat samples.txt | while read s
do
wtpoa-cns \
-t 8 \
-i redbean_assembly/${s}.ctg.lay.gz \
-fo redbean_assembly/${s}.ctg.fa
done
```

In the commands the contents of the file `samples.txt` is provided to the loop (`while read`) with a `cat` command and a pipe `|`. 

When looping through this file the commands in the loop are carried out three times, once for each sample. In future cases the loop will occur as many times as there are lines in the `samples.txt` file.

In each loop the `${s}` is replaced with the current line from the file. `s` is set as the `variable` by the user when the loop is initiated (`while read s`). `s` is arbitrary and I use it to be short for "sample" . It could be any letter or even a word, I would not recommend using only numbers.

Below we will use echo to print everything within the wtdbg2 loop to demonstrate how the loop is behaving. This will print out to screen the commands that would be run, replacing the variables (`${s}`) with the sample names. This is useful to get a sense of what the loop is actually doing. This can also be a handy way to debug your loops if they are not working as intended.

```{bash eval=FALSE}
cat samples.txt | while read s
do
echo \
"wtdbg2 \
-x rs \
-g 5.4m \
-i data/${s}.fastq \
-o redbean_assembly/${s} \
-t 8"
done
```

__Note__: Loops need to start with `do` and end with `done` as shown in the commands.

## Continuing the workflow
```{r, fig.align = 'center',out.width= '10%', echo=FALSE}
knitr::include_graphics(path = "figures/workflow_standard.png", auto_pdf = TRUE)
``` 

With this quick intro to using `while loops` and the Standard workflow bookdown, complete the genome assembly and annotation for these three samples. Finish off with one final `MultiQC` report containing the final `QUAST` , `BUSCO`, and `Prokka` info for all the samples.

__Notes__: 

- `QUAST`: This command can be provided multiple assembly files at once so a loop won't be needed.
- `BUSCO`: Ensure you use the correct lineage dataset for _Bacillus cereus_.
- `MultiQC`: Like QUAST no loop is required for this command.

To get the corrected reads, required for circularisation, please run the below commands in your `multi_sample_workflow` directory.

```{bash eval=FALSE}
#Copy compressed directory corrected corrected reads
cp /pub39/tea/nsc006/NEOF/bact_assembly/data/corrected_reads.tar.gz .
#Uncompress directory
tar -xzvf corrected_reads.tar.gz
#List contents of uncompressed directory
ls corrected_reads
```

## GNU Parallel
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/gnu_parallel.png", auto_pdf = TRUE)
``` 

Loops are a convenient method for relatively quick processes or when you have the time. However, in the future you may have time constraints or a large machine you want to make the most out of. In these cases you can parallelise your processes so multiple samples are being analysed at a one time.

There a different ways to do this but the most common tool I use is `GNU Parallel`. This command allows you to state how many jobs you want to parallelise. This number is chosen based on how many cores and how much RAM each process would need versus the current availability of the machine you are working on. Keep in mind other users might be taking up the machine's processes. The command `top` allows you to see the current load on a machine.

`GNU Parallel` will put on a new job once a job has finished. I.e. if you have four jobs on at once, with 4 waiting, the fifth job will be put on once one of the first four finish (depending on which finished first). Compare this to another tool that can put put on multiple jobs/processes at once, such as `xargs`. If you put on four jobs/processes at once with `xargs` it will wait for the first four processes to all finish before putting on the next four. This can increase the time of analysis due to some samples taking much longer than others, as visualised below.

```{r, fig.align = 'center',out.width= '60%', echo=FALSE }
knitr::include_graphics(path = "figures/xargs_vs_gnu_parallel.png", auto_pdf = TRUE)
```

Each coloured block is a different job with the width showing the time it takes to run. With four jobs/processes being parallelised at once the same 8 jobs are finished with `GNU Parallel` quicker than with `xargs`.

<!--chapter:end:02-Multi-sample_workflow.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# High coverage {#coverage}
```{r, fig.align = 'center',out.width= '20%', echo=FALSE}
knitr::include_graphics(path = "figures/wifi_coverage.png", auto_pdf = TRUE)
``` 

Low sequence coverage (<20X) can cause assembly issues due to:

- Under represented areas of the genomes. 
   - Sequencing will not lead to uniform coverage across the genome and so the lower coverage areas may not be missing of have very low coverage.
- Errors cannot be corrected/polished.
   - Low coverage may mean there are areas which do not have enough sequences to produce an accurate consensus.
   
Low sequence coverage can be corrected by carrying out more sequencing. 

High sequence coverage (>100X) may seem perfect but it can cause assembly issues. As coverage increases the number of errors in the data increases (even if the % of errors is stable). If data contains a 10% error rate then 100 megabases will contain 10 megabases of errors whilst 1 gigabase will contain 100 megabases of errors. It is a lot easier for an assembler to determine what may be errors if there is a smaller total amount of them. 

The errors will confuse the assembler and it may create create an assembly graph that looks like a bowl of spaghetti rather than one long spaghetti strand. If you provide enough coverage the assembler may never finish or crash due to memory limitations as it tries to disentangle the graph.

How do we prevent this?

## Detecting high coverage
```{r, fig.align = 'center',out.width= '10%', echo=FALSE}
knitr::include_graphics(path = "figures/altimeter.png", auto_pdf = TRUE)
``` 

To detect high coverage (>100X) you will need to first know the estimate size of your genome. Then you can look at the sequencing summary to hopefully find the number of bases in your sequencing data. If you do not have this we can use some quick unix commands to do this.

```{bash eval=FALSE}
#Move into the directory with your ecoli reads
cd ~/bacterial_assembly/standard_workflow/ecoli_reads
#Print out to screen the number of bases in ecoli.fastq
cat ecoli.fastq | paste - - - - | cut -f 2 | wc -c
```

The command consists of multiple parts with the parts piping (`|`) their outputs to be the next command's input. The parts are:

- `cat ecoli.fastq` : read `ecoli.fastq` to use it as the initial input for the commands.
- `paste - - - -` : This separates the lines into columns. Four columns are specified here by `- - - -`. As each fastq entry consists of four lines this works perfectly to create a header, a sequence, a quality header, and a quality column.
- `cut -f 2` : `cut` will extract our field/column (`-f`) of choice. In this case it is the 2nd field as all the sequence data is in the second field. Therefore we have removed all non sequence information.
- `wc -c` : `wc` stands for word count and the `-c` options stands for characters. This counts all the characters.

With this we can find out if we may have too much coverage. In this case 139,252,345bp is about 30X for a 4.6m genome (_E.coli_) so we are not worried about the coverage being too high.

## Subsampling
```{r, fig.align = 'center',out.width= '10%', echo=FALSE}
knitr::include_graphics(path = "figures/subsample.png", auto_pdf = TRUE)
``` 

To reduce the coverage we can subsample the reads. This is the act of randomly extracting reads (without replacement) to a set number or fraction. As the process is random it should not add in any bias (or at least any more bias than is present in sequencing anyway).

We will use `Seqtk` along with its option `subsample` to extract half (0.5) of the ecoli reads in the hopes we will be left with slightly more than 50Mbp.

__Note__: Use the `Conda` environment `bacterial_assembly`.

```{bash eval=FALSE}
seqtk sample -s 100 ecoli.fastq 0.5 > ecoli_subsample.fastq
```

__Parameters__

- `-s 100` : This indicates the random seed to be used for subsampling.
   - This can be any number and is arbitrarily chosen.
   - With Paired reads this number must be the same for the forward and reverse reads. This is to ensure the two files have matching reads.
- `ecoli.fastq` : The first flagless parameter to indicate the input fastq file.
- `0.5` : The second flagless parameter to indicate the subsample size.
   - If the number is a fraction (0.5, 0.2, 0.87 etc.) then the specified fraction of reads (compared to the intial total) will be extracted.
   - if the number is a whole number (1, 100, 98762 etc.) the specified number of reads will be extracted.
   
As we extract by number/fraction of reads and the size of PacBio and ONT reads vary we may not get the number of bases we desire. It is therefore always good to count the number of bases in our subsampled file.

```{bash eval=FALSE}
cat ecoli_subsample.fastq | paste - - - - | cut -f 2 | wc -c
```

__Tasks__

- Using `seqtk sample` attempt to subsample the data so you retain ~10X coverage (44-48Mbp). What fraction/number did you use?
- Try out different seed numbers, with the same subsample number/fraction, to see the effect it has on subsampling.

__Note__ There is probably no reason you would want 10X in real life this is just for practice.

I generally suggest only carrying out random subsampling if you have very high coverage (>100X) and trying to get a coverage close to 100X (95-100X). It does not have to be very exact as even a coverage of 80X would be very good for a bacterial genome.

<!--chapter:end:03-High_coverage.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Hybrid assembly {#hybrid}
```{r, fig.align = 'center',out.width= '20%', echo=FALSE}
knitr::include_graphics(path = "figures/hybrid_car.png", auto_pdf = TRUE)
``` 

Hybrid assembly methods can be used when you have long read (PacBio or ONT) and short read (Illumina) sequencing data for your samples. There are two main methods for this.

1. Using both short read and long read data during the assembly step (`hybridSPAdes`)
2. Assemble with the long reads and polish with the short reads (`pilon`)

## Hybrid assembly: Conda environment & directory
```{r, fig.align = 'center',out.width= '10%', echo=FALSE }
knitr::include_graphics(path = "figures/conda.png", auto_pdf = TRUE)
``` 

We will use the `hybrid` `conda` environment for our hybrid assembly methods.

Activate the environment:

```{bash eval=FALSE}
chos 8
. usehybrid
```

Before running any commands we will get the Illumina and PacBio data directories setup.

```{bash eval=FALSE}
#Change directory to bacterial_assembly directory
cd ~/bacterial_assembly/
#Make a hybrid analysis directory
mkdir hybrid_methods
#Move into the hybrid_methods directory
cd hybrid_methods
#Make directories to contain softlinks for Illumina and PacBio data
mkdir illumina_data
mkdir pacbio_data
#Make softlinks of E.coli sequencing data
ln -s /pub39/tea/nsc006/NEOF/bact_assembly/illumina_data/* illumina_data
ln -s /pub39/tea/nsc006/NEOF/bact_assembly/data/ecoli.fastq pacbio_data
```

## hybridSPAdes
```{r, fig.align = 'center',out.width= '15%', echo=FALSE}
knitr::include_graphics(path = "figures/spades.png", auto_pdf = TRUE)
``` 

A popular hybrid assembler for bacterial genomes is `hybridSPAdes`. It's use is very similar to just using Illumina data. The only difference is the addition of the `--pacbio` for PacBio reads or `--nanopore` for Oxford nanopore reads.

First we will create an output directory for `HybridSPAdes`.

```{bash eval=FALSE}
#Main output directory
mkdir hybridspades
#Ouptut directory for our sample
mkdir hybridspades/ecoli
```

Now to run `HybridSPAdes` with our Illumina and PacBio data.

```{bash eval=FALSE}
spades.py \
-1 illumina_data/ecoli_R1.fastq \
-2 illumina_data/ecoli_R2.fastq \
--pacbio pacbio_data/ecoli.fastq \
-o hybridspades/ecoli \
-t 8 -m 50
```

__Note__: This command will take about 10 minutes.

__Parameters__:

- `-1` : The forward paired-end reads.
- `-2` : The reverse paired-end reads.
- `--pacbio` : Provide PacBio reads for a hybrid assembly.
   - `--nanopore` : Used for ONT data.
- `-o` : The output directory.
- `-t` : The number of threads to be used with the process (default is 16).
- `-m` : The max RAM (in Gb) to be used for the assembly (default is 250Gb).

`SPAdes` can be very memory (RAM) hungry. This can be dangerous as using too much RAM is an easy way to crash the machine you are using. The flag `-m` is very good to prevent this . Additionally, decreasing the number of threads (`-t`) will decrease the RAM load.

Next view the output directory of this command.

```{bash eval=FALSE}
ls hybridspades/ecoli
```

You will notice a lot of output. Most of this can be deleted (especially the directories starting with `K`). The actually assembly in fasta format is the file `contigs.fasta`.

For more info on all the output please see: https://github.com/ablab/spades#spadesoutsec

## Pilon
```{r, fig.align = 'center',out.width= '15%', echo=FALSE}
knitr::include_graphics(path = "figures/pilon.png", auto_pdf = TRUE)
``` 

Another method for a hybrid approach is to carry out the standard workflow using only the long reads and then polish with short (Illumina) reads.

In this case we are going to carry out polishing using the tool `Pilon`. In theory assembling with the long reads is good to produce a very continuous assembly and then polishing with Illumina reads should drastically improve the quality and accuracy.

First we will make a directory and make a softlink of the circularised genome assembly from the standard workflow.

```{bash eval=FALSE}
#Move to main directory
#Change directory to bacterial_assembly directory
cd ~/bacterial_assembly/hybrid_methods
#Make assembly for long read assembly
mkdir long_read_assembly
#Softlink of assembly
#Using a premade file in case you don't have yours
ln -s /pub39/tea/nsc006/NEOF/bact_assembly/standard_workflow/ecoli.fasta long_read_assembly
```

The next part is to align our Illumina reads to our assembly. This is similar to the process for `Racon`. 

First we index the assembly.

```{bash eval=FALSE}
bwa index long_read_assembly/ecoli.fasta
```

Next we align our reads to the assembly we want polished. We carry this out with `bwa` which aligns Illumina reads by default.

```{bash eval=FALSE}
#Create output directory
mkdir -p pilon/ecoli
#Align the reads
bwa mem \
long_read_assembly/ecoli.fasta \
illumina_data/ecoli_R1.fastq \
illumina_data/ecoli_R2.fastq > \
pilon/ecoli/aln_i1.sam
```

__Note__: We have included `i1` in the output file to indicate  this is the first polishing iteration.

`Pilon` requires an indexed sorted `BAM` file. We will use `samtools` to produce this from our `SAM` file.

```{bash eval=FALSE}
#Create a bam file from the sam file
samtools view -Sb pilon/ecoli/aln_i1.sam > pilon/ecoli/aln_i1.bam
#Delete the old sam file
rm pilon/ecoli/aln_i1.sam
#Sort the bam file
samtools sort pilon/ecoli/aln_i1.bam -o pilon/ecoli/aln_i1.sort.bam
#delete the original bam file
rm pilon/ecoli/aln_i1.bam
#Index the sorted bam file
samtools index pilon/ecoli/aln_i1.sort.bam
```

Now we have a sorted `.bam` file and a `.bam.bai` file that contains the index information.

With this we can carry out `Pilon` polishing. `Pilon` is a `java` based program so we need to set the max memory (RAM) outside of the actual command. We'll assign the max RAM of all future java based programs within the current terminal (including `Pilon`) to 30 Gb.

```{bash eval=FALSE}
export _JAVA_OPTIONS="-Xmx30g"
```

__Yes__, the `_` before `JAVA` needs to be there. For more info on Java heap sizes check out: https://alvinalexander.com/blog/post/java/java-xmx-xms-memory-heap-size-control/

With the maximum memory set to 30Gb (the default size is too low) we can run our first iteration of `Pilon`.

```{bash eval=FALSE}
pilon \
--genome long_read_assembly/ecoli.fasta \
--frags pilon/ecoli/aln_i1.sort.bam \
--outdir pilon/ecoli/ \
--output ecoli_i1 \
--changes 
```

__Parameters__

- `--genome` : The input genome to be polished.
- `--frags` : `BAM` containing fragment paired-end alignment using `bwa` or `bowtie2`.
   - There are other options for other types of Illumina reads and sequencing technologies than can be checked using `pilon --help | less`.
- `--outdir` : Output directory for all output files.
- `--output` : Set the prefix for output files.
- `--changes` : This will produce a file listing the polishing changes. More info below.

In the output directory there will be two files:

1. `ecoli_i1.fasta` : The polished fasta file.
2. `ecoli_i1.changes` : This file lists all the changes polishing carried out. There is one line per change.

Let us find out how many changes `Pilon` polishing carried out:

```{bash eval=FALSE}
wc -l pilon/ecoli/ecoli_i1.changes
```

That is a lot of changes! 

__Task__

It would be good to polish the genome again. Therefore polish it once more using:

- The `Pilon` method like above.
- The pilon polished assembly `pilon/ecoli/ecoli_i1.fasta` as the input for the `bwa` and `pilon` commands.
- `i2` instead of `i1` for the new files you make.

Once polishing is done check the number of changes. Has the number decreased a lot?

## Hybrid approaches recap
```{r, fig.align = 'center',out.width= '15%', echo=FALSE}
knitr::include_graphics(path = "figures/recap.png", auto_pdf = TRUE)
``` 

Great now you can carry out hybrid assembly and polishing with short reads. If you produce a hybrid assembly it may also be a good idea to polish the assembly with `Racon` or `Pilon`.

<!--chapter:end:04-Hybrid_assembly.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# (APPENDIX) Appendix {-}

# Next steps{#nextsteps}
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/step.png", auto_pdf = TRUE)
``` 

- Unix Loop tutorial
   - https://swcarpentry.github.io/shell-novice/05-loop/index.html

# Manuals{#manuals}
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/manual.png", auto_pdf = TRUE)
``` 

sed - https://www.gnu.org/software/sed/manual/sed.html

GNU Parallel - https://www.gnu.org/software/parallel/

Seqtk - https://github.com/lh3/seqtk

HybridSPAdes - http://cab.spbu.ru/files/release3.11.1/manual.html

Pilon - https://github.com/broadinstitute/pilon

samtools - http://www.htslib.org/

# Data

_B.cereus_ reference genomes:

- https://www.ncbi.nlm.nih.gov/nuccore/NZ_CP024655?report=fasta
- https://www.ncbi.nlm.nih.gov/nuccore/CP068719.1?report=fasta
- https://www.ncbi.nlm.nih.gov/nuccore/CP043966?report=fasta


<!--chapter:end:05-Appendix.Rmd-->

