[["01-Bacterial_genome_supplemental.html", "Bacterial genome assembly and annotation supplemental Chapter 1 Supplemental", " Bacterial genome assembly and annotation supplemental Matthew R. Gemmell 2022-06-09 Chapter 1 Supplemental This bookdown is a supplement to the main one. It contains some workflows and tools that are not part of the standard workflow. However, they may prove useful depending on your needs. The sections in this supplement will cover: Running the standard workflow with multiple samples Having too much sequencing coverage Using long and short reads in hybrid assembly approaches Commands are in the following font, colour, and box.They should be run in the command line. echo &quot;This is a command example&quot; This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Multi-sample_workflow.html", "Chapter 2 Multiple sample workflow 2.1 Raw data of multiple samples 2.2 Sample file 2.3 Start looping 2.4 Continuing the workflow 2.5 GNU Parallel", " Chapter 2 Multiple sample workflow In the standard workflow bookdown we assembled and annotated a single sample/genome. In your future projects you will most likely need to carry this out for multiple samples. This could be carried out by running each command for each sample separately. However, there are much quicker methods. In this section I will introduce you to my preferred method of carrying out commands on multiple samples. This involves a text file containing all the samples names in conjunction with while read loops. 2.1 Raw data of multiple samples Prior to running the analysis we will need the data and an analysis directory. #Move to your bacterial_assembly directory cd ~/bacterial_assembly/ #Create a multi_sample_workflow directory with a data subdirectory mkdir -p multi_sample_workflow/data #Move into the new analysis directory cd multi_sample_workflow We will be running three Bacillus cereus samples through the standard workflow. We'll create softlinks of the PacBio fastq files. It is always good to use softlinks for read data if you are not going to move it from its original location. Softlinks are like file shortcuts. It is much quicker to create a softlink than copy data and it means you are not using unneeded storage to store the data multiple times. #Softlink the PacBio fastq files we will use ln -s /pub39/tea/nsc006/NEOF/bact_assembly/multi_sample_workflow/* data/ #List contents of the data directory ls data Note When creating a softlink you should always use absolute (whole) paths for the original file/s you specify. 2.2 Sample file Now it is time to make the sample file we will use for the future while read loops. This file will contain the sample names, one sample name per line. For ease and convenience we will change the prefix of our PacBio fastq files to that of our desired samples names. In this case it is removing the _0001 part. We could rename all the files with the mv command but this might be awkward with many files. Instead we will use the rename command #Move into the data directory cd data #Rename the files rename &quot;s/_0001//&quot; *.fastq #List contents ls . rename will rename all indicated files (*.fastq = all files in current directory with the suffix .fastq) using syntax similar to the sed command. The \"s/_0001//\" is made of four parts: s/: The s indicates we are carrying out a substitution. We will substitute regular expressions (i.e. pattern) for a replacement. /_0001/: The first instance of _0001 is to be substituted. This is the regular expression. //: The matched pattern (_0001) is to be substituted with nothing. This is the replacement. The end, after the last /: Contains any flags to be provided to the substitution command. The most commonly used flag is g which stands for global substitution. This will cause substitutions to occur for every instance of the regular expression found. The default is that only the first instance of the regular expression will be replaced. For more info on sed please the Intro to Unix bookdown. With our newly named softlinks we can quickly create our sample file. #List fastq files ls *fastq #List fastq files and remove the suffix (i.e. list sample names) ls *fastq | sed &quot;s/.fastq//&quot; #Redirect sample names to a new sample file ls *fastq | sed &quot;s/.fastq//&quot; &gt; ../samples.txt Move up one directory to the main analysis directory and view the contents of the sample file. #Move up one directory cd .. #Print samples.txt contents to screen cat samples.txt 2.3 Start looping Now that we have our data and our sample file we can start carrying out the standard workflow with loops. Run the below example while read loop to see its output. cat samples.txt | while read s ; do echo &quot;File for sample ${s} is ${s}.fastq&quot; ; done Ensure you are in a terminal with an active bacterial_assembly environment then create an assembly output directory. mkdir redbean_assembly Now to run the redbean assembly steps with loops #wtdbg2 step cat samples.txt | while read s do wtdbg2 \\ -x rs \\ -g 5.4m \\ -i data/${s}.fastq \\ -o redbean_assembly/${s} \\ -t 8 done #Derive consensus cat samples.txt | while read s do wtpoa-cns \\ -t 8 \\ -i redbean_assembly/${s}.ctg.lay.gz \\ -fo redbean_assembly/${s}.ctg.fa done In the commands the contents of the file samples.txt is provided to the loop (while read) with a cat command and a pipe |. When looping through this file the commands in the loop are carried out three times, once for each sample. In future cases the loop will occur as many times as there are lines in the samples.txt file. In each loop the ${s} is replaced with the current line from the file. s is set as the variable by the user when the loop is initiated (while read s). s is arbitrary and I use it to be short for \"sample\" . It could be any letter or even a word, I would not recommend using only numbers. Below we will use echo to print everything within the wtdbg2 loop to demonstrate how the loop is behaving. This will print out to screen the commands that would be run, replacing the variables (${s}) with the sample names. This is useful to get a sense of what the loop is actually doing. This can also be a handy way to debug your loops if they are not working as intended. cat samples.txt | while read s do echo \\ &quot;wtdbg2 \\ -x rs \\ -g 5.4m \\ -i data/${s}.fastq \\ -o redbean_assembly/${s} \\ -t 8&quot; done Note: Loops need to start with do and end with done as shown in the commands. 2.4 Continuing the workflow With this quick intro to using while loops and the Standard workflow bookdown, complete the genome assembly and annotation for these three samples. Finish off with one final MultiQC report containing the final QUAST , BUSCO, and Prokka info for all the samples. Notes: QUAST: You can provide this command with multiple assembly files at once so a loop won't be needed. BUSCO: Ensure you use the correct lineage dataset for Bacillus cereus. MultiQC: Like QUAST no loop is required for this command. To get the corrected reads, required for circularisation, please run the below commands in your multi_sample_workflow directory. #Copy compressed directory corrected corrected reads cp /pub39/tea/nsc006/NEOF/bact_assembly/data/corrected_reads.tar.gz . #Uncompress directory tar -xzvf corrected_reads.tar.gz #List contents of uncompressed directory ls corrected_reads 2.5 GNU Parallel Loops are a convenient method for relatively quick processes or when you have the time. However, in the future you may have time constraints or a large machine you want to make the most out of. In these cases you can parallelise your processes so multiple samples are being analysed at the same time. There a different ways to do this but the most common tool I use is GNU Parallel. This command allows you to state how many jobs you want to parallelise. This number is chosen based on how many cores and how much RAM each process would need versus the current availability of the machine you are working on. Keep in mind other users might be taking up the machine's processes. The command top allows you to see the current load on a machine. GNU Parallel will put on a new job once a job has finished. I.e. if you have four jobs on at once, with 4 waiting, the fifth job will be put on once one of the first four finish (depending on which finished first). Compare this to another tool that can put put on multiple jobs/processes at once, such as xargs. If you put on four jobs/processes at once with xargs it will wait for the first four processes to all finish before putting on the next four. This can increase the time of analysis due to some samples taking much longer than others, as visualised below. Each coloured block is a different job with the width showing the time it takes to run. With four jobs/processes being parallelised at once the same 8 jobs are finished with GNU Parallel quicker than with xargs. "],["03-High_coverage.html", "Chapter 3 High coverage 3.1 Detecting high coverage 3.2 Subsampling", " Chapter 3 High coverage Low sequence coverage (&lt;20X) can cause assembly issues due to: Under represented areas of the genomes. Sequencing will not lead to uniform coverage across the genome and so the lower coverage areas may not be missing of have very low coverage. Errors cannot be corrected/polished. Low coverage may mean there are areas which do not have enough sequences to produce an accurate consensus. Low sequence coverage can be corrected by carrying out more sequencing. High sequence coverage (&gt;100X) may seem perfect but it can cause assembly issues. As coverage increases the number of errors in the data increases (even if the % of errors is stable). If data contains a 10% error rate then 100 megabases will contain 10 megabases of errors whilst 1 gigabase will contain 100 megabases of errors. It is a lot easier for an assembler to determine what may be errors if there is a smaller total amount of them. The errors will confuse the assembler and it may create create an assembly graph that looks like a bowl of spaghetti rather than one long spaghetti strand. If you provide enough coverage the assembler may never finish or it will crash due to memory limitations as it tries to disentangle the graph. How do we prevent this? Read on to find out one method. 3.1 Detecting high coverage To detect high coverage (&gt;100X) you will need to first know the estimated size of your genome. Then you can look at the sequencing summary to hopefully find the number of bases in your sequencing data. If you do not have this we can use some quick unix commands to do this. #Move into the directory with your ecoli reads cd ~/bacterial_assembly/standard_workflow/ecoli_reads #Print out to screen the number of bases in ecoli.fastq cat ecoli.fastq | paste - - - - | cut -f 2 | wc -c The command consists of multiple parts with the parts piping (|) their outputs to be the next command's input. The parts are: cat ecoli.fastq : read ecoli.fastq to use it as the initial input for the commands. paste - - - - : This separates the lines into columns. Four columns are specified here by - - - -. As each fastq entry consists of four lines this works perfectly to create a header, a sequence, a quality header, and a quality column. cut -f 2 : cut will extract our field/column (-f) of choice. In this case it is the 2nd field as all the sequence data is in the second field. Therefore we have removed all non sequence information. wc -c : wc stands for word count and the -c options stands for characters. This counts all the characters. This will therefore count all the bases within our fastq file. With this we can find out if we may have too much coverage. In this case 139,252,345bp is about 30X for a 4.6m genome (E.coli) so we are not worried about the coverage being too high. 3.2 Subsampling To reduce the coverage we can subsample the reads. This is the act of randomly extracting reads (without replacement) to a set number or fraction. As the process is random it should not add in any bias (or at least any more bias than is present in sequencing anyway). We will use seqtk along with its option subsample to extract half (0.5) of the ecoli reads in the hopes we will be left with slightly more than 50Mbp. Note: Use the Conda environment bacterial_assembly. seqtk sample -s 100 ecoli.fastq 0.5 &gt; ecoli_subsample.fastq Parameters -s 100 : This indicates the random seed to be used for subsampling. This can be any number and is arbitrarily chosen. With Paired reads this number must be the same for the forward and reverse reads. This is to ensure the two files have matching reads. ecoli.fastq : The first flagless parameter to indicate the input fastq file. 0.5 : The second flagless parameter to indicate the subsample size. If the number is a fraction (0.5, 0.2, 0.87 etc.) then the specified fraction of reads (compared to the intial total) will be extracted. if the number is a whole number (1, 100, 98762 etc.) the specified number of reads will be extracted. As we have extracted by the number/fraction of reads and the size of PacBio and ONT reads vary we may not get the number of bases we desire. It is therefore always good to count the number of bases in our subsampled file. cat ecoli_subsample.fastq | paste - - - - | cut -f 2 | wc -c Tasks Using seqtk sample attempt to subsample the data so you retain ~10X coverage (44-48Mbp). What fraction/number did you use? Try out different seed numbers, with the same subsample number/fraction, to see the effect it has on subsampling. Note There is probably no reason you would want 10X in real life this is just for practice. I generally suggest only carrying out random subsampling if you have very high coverage (&gt;100X) and trying to get a coverage close to 100X (95-100X). It does not have to be very exact as even a coverage of 80X would be very good for a bacterial genome. "],["04-Hybrid_assembly.html", "Chapter 4 Hybrid assembly 4.1 Hybrid assembly: Conda environment &amp; directory 4.2 hybridSPAdes 4.3 Pilon 4.4 Hybrid approaches recap", " Chapter 4 Hybrid assembly Hybrid assembly methods can be used when you have long read (PacBio or ONT) and short read (Illumina) sequencing data for your samples. There are two main methods for this. Using both short read and long read data during the assembly step (hybridSPAdes) Assemble with the long reads and polish with the short reads (pilon) 4.1 Hybrid assembly: Conda environment &amp; directory We will use the hybrid conda environment for our hybrid assembly methods. Activate the environment in a new terminal: chos 8 . usehybrid Before running any commands we will get the Illumina and PacBio data directories setup. #Change directory to bacterial_assembly directory cd ~/bacterial_assembly/ #Make a hybrid analysis directory mkdir hybrid_methods #Move into the hybrid_methods directory cd hybrid_methods #Make directories to contain softlinks for Illumina and PacBio data mkdir illumina_data mkdir pacbio_data #Make softlinks of E.coli sequencing data ln -s /pub39/tea/nsc006/NEOF/bact_assembly/illumina_data/* illumina_data ln -s /pub39/tea/nsc006/NEOF/bact_assembly/data/ecoli.fastq pacbio_data 4.2 hybridSPAdes A popular hybrid assembler for bacterial genomes is hybridSPAdes. It's hybrid usage is very similar to only using Illumina data. The only difference is the addition of the --pacbio for PacBio reads or --nanopore for Oxford nanopore reads. First we will create an output directory for HybridSPAdes. #Main output directory mkdir hybridspades #Ouptut directory for our sample mkdir hybridspades/ecoli Now to run HybridSPAdes with our Illumina and PacBio data. spades.py \\ -1 illumina_data/ecoli_R1.fastq \\ -2 illumina_data/ecoli_R2.fastq \\ --pacbio pacbio_data/ecoli.fastq \\ -o hybridspades/ecoli \\ -t 8 -m 50 Note: This command will take about 10 minutes. Parameters: -1 : The forward paired-end reads. -2 : The reverse paired-end reads. --pacbio : Provide PacBio reads for a hybrid assembly. --nanopore : Used for ONT data. -o : The output directory. -t : The number of threads to be used with the process (default is 16). -m : The max RAM (in Gb) to be used for the assembly (default is 250Gb). SPAdes can be very memory (RAM) hungry. This can be dangerous as using too much RAM is an easy way to crash the machine you are using. The flag -m is very good to prevent this . Additionally, decreasing the number of threads (-t) will decrease the RAM load. Next view the output directory of this command. ls hybridspades/ecoli You will notice a lot of output. Most of this can be deleted (especially the directories starting with K). The actually assembly in fasta format is the file contigs.fasta. For more info on all the output please see: https://github.com/ablab/spades#spadesoutsec 4.3 Pilon Another method for a hybrid approach is to carry out the standard workflow using only the long reads and then polish with short (Illumina) reads. In this case we are going to carry out polishing using the tool Pilon. In theory assembling with the long reads is good to produce a very continuous assembly and then polishing with Illumina reads should drastically improve the quality and accuracy. First we will make a directory and make a softlink of the circularised genome assembly from the standard workflow. #Move to main directory #Change directory to bacterial_assembly directory cd ~/bacterial_assembly/hybrid_methods #Make assembly for long read assembly mkdir long_read_assembly #Softlink of assembly #Using a premade file in case you don&#39;t have yours ln -s /pub39/tea/nsc006/NEOF/bact_assembly/standard_workflow/ecoli.fasta \\ long_read_assembly The next part is to align our Illumina reads to our assembly. This is similar to the process for Racon. First we index the assembly. bwa index long_read_assembly/ecoli.fasta Next we align our reads to the assembly we want polished. We carry this out with bwa which aligns Illumina reads by default. #Create output directory mkdir -p pilon/ecoli #Align the reads bwa mem \\ long_read_assembly/ecoli.fasta \\ illumina_data/ecoli_R1.fastq \\ illumina_data/ecoli_R2.fastq &gt; \\ pilon/ecoli/aln_i1.sam Note: We have included i1 in the output file to indicate this is the first polishing iteration. Pilon requires an indexed sorted BAM file. We will use samtools to produce this from our SAM file. #Create a bam file from the sam file samtools view -Sb pilon/ecoli/aln_i1.sam &gt; pilon/ecoli/aln_i1.bam #Delete the old sam file rm pilon/ecoli/aln_i1.sam #Sort the bam file samtools sort pilon/ecoli/aln_i1.bam -o pilon/ecoli/aln_i1.sort.bam #delete the original bam file rm pilon/ecoli/aln_i1.bam #Index the sorted bam file samtools index pilon/ecoli/aln_i1.sort.bam Now we have a sorted .bam file and a .bam.bai file that contains the index information. With this we can carry out Pilon polishing. Pilon is a java based program so we need to set the max memory (RAM) outside of the actual command. We'll assign the max RAM of all future java based programs within the current terminal (including Pilon) to 30 Gb. export _JAVA_OPTIONS=&quot;-Xmx30g&quot; Yes, the _ before JAVA needs to be there. For more info on Java heap sizes check out: https://alvinalexander.com/blog/post/java/java-xmx-xms-memory-heap-size-control/ With the maximum memory set to 30Gb (the default size is too low) we can run our first iteration of Pilon. pilon \\ --genome long_read_assembly/ecoli.fasta \\ --frags pilon/ecoli/aln_i1.sort.bam \\ --outdir pilon/ecoli/ \\ --output ecoli_i1 \\ --changes Parameters --genome : The input genome to be polished. --frags : BAM containing fragment paired-end alignment using bwa or bowtie2. There are other options for other types of Illumina reads and sequencing technologies than can be checked using pilon --help | less. --outdir : Output directory for all output files. --output : Set the prefix for output files. --changes : This will produce a file listing the polishing changes. More info below. In the output directory there will be two files: ecoli_i1.fasta : The polished fasta file. ecoli_i1.changes : This file lists all the changes polishing carried out. There is one line per change. Let us find out how many changes Pilon polishing carried out: wc -l pilon/ecoli/ecoli_i1.changes That is a lot of changes! Task It would be good to polish the genome again. Therefore polish it once more using: The Pilon method like above. The pilon polished assembly pilon/ecoli/ecoli_i1.fasta as the input for the bwa and pilon commands. i2 instead of i1 for the new files you make. Once polishing is done check the number of changes. Has the number decreased a lot compared to the changes made by the first round of polishing? 4.4 Hybrid approaches recap Great now you can carry out hybrid assembly and polishing with short reads. If you produce a hybrid assembly it may also be a good idea to polish the assembly with Racon or Pilon. "],["05-Appendix.html", "A Next steps B Manuals C Data", " A Next steps Unix Loop tutorial https://swcarpentry.github.io/shell-novice/05-loop/index.html B Manuals sed - https://www.gnu.org/software/sed/manual/sed.html GNU Parallel - https://www.gnu.org/software/parallel/ Seqtk - https://github.com/lh3/seqtk HybridSPAdes - http://cab.spbu.ru/files/release3.11.1/manual.html Pilon - https://github.com/broadinstitute/pilon samtools - http://www.htslib.org/ C Data B.cereus reference genomes: https://www.ncbi.nlm.nih.gov/nuccore/NZ_CP024655?report=fasta https://www.ncbi.nlm.nih.gov/nuccore/CP068719.1?report=fasta https://www.ncbi.nlm.nih.gov/nuccore/CP043966?report=fasta "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
