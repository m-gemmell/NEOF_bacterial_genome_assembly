[["01-Bacterial_genome_assembly_and_annotation.html", "Bacterial genome assembly and annotation Chapter 1 Introduction", " Bacterial genome assembly and annotation Matthew R. Gemmell 2022-06-08 Chapter 1 Introduction This practical session will run you through a standard bacterial genome assembly and annotation workflow using PacBio data. The topics covered are: Setup Overview Genome assembly with Redbean (wtdbg2) Assembly assessment Polishing with arrow Circularisation with Circlator Annotation with Prokka Final report generation with MultiQC The aim of this practical is to produce a genome assembly of Eschrichia coli, annotate it, and produce a report with the assembly's stats. Read QC will be skipped as this has been covered in a previous NEOF workshop. Commands are in the following font, colour, and box.They should be run in the command line. echo &quot;This is a command example&quot; "],["02-Cluster_Introduction.html", "Chapter 2 Cluster Introduction 2.1 Logon instructions 2.2 The Terminal Window", " Chapter 2 Cluster Introduction 2.1 Logon instructions For this workshop we will be using Virtual Network Computing (VNC). Connect to the VNC with a browser by using the webVNC link you were sent. You will now be in a logged-in Linux VNC desktop. You will see something as below (there may be only one terminal which is fine). If you do not see something similar please ask for assistance. If the VNC is taking up too much/little space of your browser you can use the zoom of your browser to adjust the size. Ensure you can see one whole terminal. These instructions will not work outside of this workshop. If you would like to install your own Linux OS on your desktop or laptop we would recommend Ubuntu. The following link is a guide to install Ubuntu: https://www.ubuntu.com/download/desktop/install-ubuntu-desktop. If you use a USB you need to create a bootable USB stick. The following link will assist: https://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows 2.2 The Terminal Window In our case the terminal window looks like the picture below. We are using the terminal window as our shell to interpret our commands to the kernel. Depending on your system and preferences it may look different. Already there is useful information for us on the terminal window. nsc065: This is the login name, also known as the username. In this case nsc065 is a demonstrator's account. Your screen should show a different account name which will be your username for the Linux machine/cluster you are logged into. gauss03: This is the machine name the user is logged into. ~: This represents the current directory of the user, or the directory a command was run in. In the Linux OS and others '~' is a shortcut to the user's home directory. Everything after the '$' is where commands are typed into the terminal. This is also referred to as the command line. To open a new terminal window, right click on the main screen, choose Applications -&gt; Shell -&gt; bash "],["03-Start.html", "Chapter 3 Setup 3.1 Workshop directory &amp; data 3.2 Conda environments", " Chapter 3 Setup 3.1 Workshop directory &amp; data Prior to starting analysis we will create a working directory. The directory ~/bacterial_assembly/standard_workflow will contain all the inputs and outputs of our analyses. #Make directory mkdir -p ~/bacterial_assembly/standard_workflow #Move into it cd ~/bacterial_assembly/standard_workflow During the workflow we will keep a tidy directory structure outputting the results form different tools into their respective directories. For the standard workflow we will be using pre QC'd PacBio reads of an Escherichia coli genome. Create a directory and create soft links (i.e. a shortcut) of the read data. #Create directory mkdir ecoli_reads #Softlink of read data ln -s /pub39/tea/nsc006/NEOF/bact_assembly/data/ecoli.fastq ecoli_reads 3.2 Conda environments Conda is a very useful tool for bioinformaticians. It allows for the creation of virtual environments so you can install different programs. This is generally easier than manually installing programs for 2 main reasons: Normally Conda will install all the dependencies a program needs. Prior to Conda it could take more than a day to install a program and all its dependencies plus the dependencies of the dependencies etc. Different programs may need different versions of the same program as a dependency (e.g. One program may need Python2 whilst another needs Python3). Therefore installing one can break the other. Having separate Conda environments (virtual environments) can isolate clashing programs. Analogy: You can think of programs as food and environments as food storage units. You could try to shove all your food into one giant cold room but most of your food will either be too cold or too warm. Instead it would be better to have different types of food in different environments as outlined in the below table. Storage environment Food examples Fridge Fresh vegetables, fresh meat, etc. Freezer Frozen meat, ice, etc. Pantry Canned food, jarred food, etc. Cellar Wine. Fruit bowl Fruit. As we will be using many different programs we will be using different Conda environments. To activate these environments you will be using use scripts that will activate the relevant Conda environment belonging to user nsc006 (Matthew Gemmell). Preferably during the course of this workflow you will have a terminal open for each Conda environment. It is important to make sure you are in the correct terminal/environment for each chapter. You can see what environment a terminal currently has activated by looking at the command prompt. In the below picture we can see the command prompt says we are in the environment called bacterial_assembly. The name of the currently activated Conda environment will always be in () before the login/user name across all systems when using Conda. For your own future analyses you would use your own Conda. If you are interested please see the Conda and Mamba links in the Next steps section of the Appendix. "],["04-Overview.html", "Chapter 4 Overview", " Chapter 4 Overview In this bookdown we will be running a standard workflow for genome assembly with long reads. This, on top of QC, can be used for PacBio and ONT data. Most of the time this will be all you need to produce a good annotated genome assembly. Below is a diagram of the workflow. Ideally you would actually run assessment after every non assessment step to make sure the various steps are performing well. This workflow will not always be effective which may require the use of other assemblers or other processes. Some of these will be covered in the supplemental bookdown. "],["05-Assembly.html", "Chapter 5 Genome Assembly 5.1 Redbean 5.2 Bandage Visualisation 5.3 Other long read assemblers", " Chapter 5 Genome Assembly The first step of any genome assembly project is to carry out QC of the read data. The very next step is genome assembly. There are many different assemblers and in the past the choice of assembler and its parameters was the primary task to produce a good quality assembly after getting good quality reads. The bioinformatician's choice of assembler and parameters is not as vital as it once was. This is due to great improvements to sequencing technologies and bioinformatics processes which include: Sequencing technologies are creating longer and higher quality reads. The better the length and quality, the less work assemblers needs to do. There may come a time when you can get one read that perfectly represents an entire genome/chromosome. Assembly would not be required at all. Genome assemblers are improving. There is a large choice of good genome assemblers. It is less a question of which to use and more a question of which not to use. Genome assembly parameter choice is a smaller issue. For older assemblers and older versions of assemblers it would take a lot of trial and error to try to find the best parameters. Now like many bioinformatics tools, assemblers will attempt to use the best parameters for your data. Generally they are better and quicker than humans at this. 5.1 Redbean For assembly of our PacBio reads we will be using Redbean (AKA wtdbg2). Redbean is a long read assembler with comparable performance to others. However, where it excels is its speed, it is much faster than other long read assemblers. This make it perfect for this workshop. Redbean can be used for genomes of all sizes. It will work for Viruses, Bacteria, Archaea, and Eukaryotes. Redbean works for PacBio RSII, PacBio Sequel, and Oxford nanopore data. 5.1.1 Redbean: Conda environment &amp; directory We will use the bacterial_assembly conda environment for our Redbean assembly. This will be our main conda environment for our standard workflow. Activate the environment: . usebacterialassembly Before we start we will move into our analysis directory (created in setup) and create a directory for the assembly we will produce. #Change directory to analysis directory cd ~/bacterial_assembly/standard_workflow #Create directory for redbean output mkdir redbean_assembly 5.1.2 Redbean: Assemble long reads The first step of Redbean is to carry out the assembly. This is carried out with the wtdgb2 command. wtdbg2 -x rs -g 4.6m -i ecoli_reads/ecoli.fastq -o redbean_assembly/ecoli -t 8 Parameters -x : This indicates the sequencing technology of the input reads. rs = PacBio RSII sq = PacBio Sequel ccs = PacBio CCS reads ont = Oxford Nanopore -g : This indicates the estimated size of the genome This does not need to be super exact with and you can round up to two significant figures. Examples are below. E.coli | genome size = 4,639,221 bp =&gt; -g 4.6m (m = megabases) Phi-X174 | genome size = 5386 bp =&gt; -g 5.4k (k = kilobase) H.Sapiens | genome size = 3.2Gb =&gt; -g 3g (g = gigabase) -i : The input reads. -o : The output prefix. With this set to redbean_assembly/ecoli all the output files will be in the directory redbean_assembly with the prefix ecoli. -t : Number of threads to be used. The will create a bunch of output files. Most of these we will ignore with only 4 being used below. 5.1.3 Redbean: Derive consensus If you checked the output directory you may have noticed there was no fasta file. Therefore the next step is to create a fasta file that contains the consensus assembly with wtpoa-cns. wtpoa-cns -t 8 -i redbean_assembly/ecoli.ctg.lay.gz -fo redbean_assembly/ecoli.ctg.fa Parameters -i : The input ctg.lay.gz file produced by wtdbg2 -fo : The output file path for the consensus assembly in fasta format. -t : Number of threads to be used. The consensus is produced from the assembly graph (more on the graph below). Assembly is not always straight forward and when producing a graph, an assembler may derive multiple paths/branches through the assembly. Two examples of how this may occur are: Repeating regions: An assembler may find it hard to determine how many times a repeat occurs within the repeat region. Maybe it is 10 or 11 times. Identical homopolymers: It is possible that long homopolymers of As (or one of the other bases) occurs multiple times in the genome. It may then be difficult to know what is at either end of each unique homopolymer location. E.g. There are 2 homopolymer sequences (H1 &amp; H2) with 4 ends (E1-4). Is H1 flanked by E1 and E2 and therefore H2 is flanked by E3 and E4? Or is H1 flanked by E1 and E3 and therefore H2 is flanked by E2 and E4? Etc. The consensus can then be thought of as the one best path through the graph to produce the most likely genome assembly. 5.2 Bandage Visualisation This part is optional and generally something I never do in real analyses. However, it is interesting and will help your understanding of assembly graphs. Redbean carries out 3 iterations of graph construction, each getting better. These three graph iterations are represented by the .dot.gz files. We can visualise these graphs with the tool Bandage. Before visualisation we need to convert the files to .gfa (link on file specs in appendix) files which are compatible with Bandage. First we need to gunzip the files. gunzip redbean_assembly/ecoli.1.dot.gz gunzip redbean_assembly/ecoli.2.dot.gz gunzip redbean_assembly/ecoli.3.dot.gz Next we convert the .dot files into .gfa files. The script wtdbg2-dot2gfa.pl is found in the scripts directory of wtdbg2 which can be found at: https://github.com/ruanjue/wtdbg2/tree/master/scripts. Unfortunately this is not installed when you install wtdbg2 via Conda. wtdbg-dot2gfa.pl redbean_assembly/ecoli.1.dot &gt; redbean_assembly/ecoli.1.dot.gfa wtdbg-dot2gfa.pl redbean_assembly/ecoli.2.dot &gt; redbean_assembly/ecoli.2.dot.gfa wtdbg-dot2gfa.pl redbean_assembly/ecoli.3.dot &gt; redbean_assembly/ecoli.3.dot.gfa Now we can open up the Bandage GUI. Bandage Using this GUI we will open the .gfa files one at a time. Start with the ecoli.1.dot.gfa file (the 1st graph), then the ecoli.2.dot.gfa file (2nd), followed by the ecoli.3.dot.gfa file (3rd, last, and best). To open a graph carry out the following On the tool bar click File -&gt; Load graph In the pop up file explorer navigate to ~/bacterial_assembly/standard_workflow/redbean_assembly/ and double click on the .gfa file you would like to view. In the Graph drawing section on the right side bar: Ensure Scope: is set to Entire graph Ensure Style is set to Single Click the Draw graph button Tips: The graph for ecoli.1.dot.gfa will take quite a while to load. The graphs for ecoli.2.dot.gfa and ecoli.3.dot.gfa are very large so you may need to change the zoom to 1%. As you go from 1 to 3 you will see two main changes: Fewer contigs: This shows the assembler is connecting parts of the assembly to give a more contiguous assembly. Fewer branches: In the 1st and 2nd graphs you will see branches, parts of the graph that branch off and possibly reconnect again. This represents multiple paths through the assembly that are possible. Through the Redbean iterations the assembler chooses the best routes, removing the other routes. You will need to zoom in to properly see these branches. 5.3 Other long read assemblers Redbean will not always be the optimal assembler. However, even if you plan to use another assembler Redbean is very good as a first pass tool due to its speed. It can be very useful to run a Redbean assembly and carry out genome assessment (shown in next chapter) to see if there are any issues with the reads that was not caught in the read QC. Various issues and solutions are covered in the supplemental bookdown. Other long read assemblers to explore for yourself include (links in appendix): Canu HGAP Flye Raven NECAT Shasta "],["06-Genome_assessment.html", "Chapter 6 Genome assembly assessment 6.1 Assessment: Conda environnment &amp; directory 6.2 QUAST 6.3 BUSCO 6.4 CheckM 6.5 Assessment recap", " Chapter 6 Genome assembly assessment After carrying out an assembly it is always advised to assess its quality. We will carry this out with three tools: QUAST - Gives assembly stats related to contiguity. BUSCO - Estimates completeness of a genome. CheckM - Estimates completeness and contamination of a genome. 6.1 Assessment: Conda environnment &amp; directory Open a new terminal (right click on the main screen, choose Applications -&gt; Shell -&gt; bash). We will use the bacterial_genome_assessment conda environment for our genome assessment tools. chos 8 . usebacterialgenomeassessment Ensure you are in the the standard_workflow directory for this new terminal and environment. cd ~/bacterial_assembly/standard_workflow 6.2 QUAST QUAST is the most used tool to assess genomes. It gives various statistics related to the contiguity of the assembly. Unless stated these statistics are based on contigs that are &gt;=500bp. Create an output directory and run QUAST. #Make output directory mkdir -p quast/redbean #Run QUAST quast -o quast/redbean redbean_assembly/ecoli.ctg.fa Parameters -o : The output directory. The input file/s are at the end of the command without a flag (e.g. -o). Note : QUAST can be run on multiple assemblies giving a report which contains info on all the input assemblies. QUAST produces reports in various formats. We will look at the html report. firefox quast/redbean/report.html Inspect the table and interact with the interactive plots. Statistics such as length, # contigs (number of contigs), and GC (%) are self explanatory. Two definitions that you may not be aware of are N50/N75 and L50/L75. To calculate N50 and L50: Order the contigs from largest to smallest. Find the point that is 50% the length of the assembly starting from the start of the largest contig going toward the smallest contig. Determine which contig this point belongs to. The N50 is equal to the length of the contig. The L50 is equal to the number of contigs that is &gt;= in length to the N50. To find the N75 &amp; L75 change the 50% to 75% in point 2. You can use any number between 1-100 for the Nx or Lx. Additionally, below is a visual demonstration of Nx and Lx. Questions How many total contigs are there? Approximately how much bigger is the total assembly compared to the largest contigs (to the nearest 1k)? Does the GC% match what is know about E.coli? (You may need to google) Why is the N50 and N75 the same? Overall these contiguity stats are good. It is not a one contig assembly, which is what we would aim for a single chromosome genome, but it is close. It mainly consists of one large contig with 3 smaller contigs. Some things you will want to look out for in future projects: High number of contigs, with small N50: This may indicate the genome assembly is very uncontiguous and so the assembler had issues with assembly. It is possible the genome is a particularly difficult genome to resolve. The input data could be poor. Examples include: Low quality. Low coverage. Average coverage could be good but it is possible areas of the genome have low coverage so these areas could not be assembled well. Length is not correct: Could be caused by several reasons: Parts of the genome are duplicated in the assembly causing the assembly to be too long. This can be caused by parts where a consensus could not be reached effectively. A short assembly can indicate that parts of the genome are missing. A drastically increased length can indicate the presence of contamination from another organism. The GC (%) can give a clue if this may be the case. Further assessment can elucidate if there are any issues and what the issue may be. 6.3 BUSCO BUSCO stands for Benchmarking Universal Single-Copy Orthologs. The tool is used to estimate the completeness of genome assemblies by determining how many BUSCOs are present. Prior to running BUSCO we will create an output directory for the BUSCO analysis. mkdir -p busco/redbean BUSCOs are genes that are: Universal: The genes are present in all organisms of a specific lineage. Single-Copy: The genes are only found as one copy. BUSCO has many different lineage datasets. These are datasets of the different groups of BUSCOs found in various different lineages. Carry out the below command to see all these different datasets. busco --list-datasets | less -S You will notice that the lineage datasets are at various taxonomic levels going from kingdom (bacteria, archaea, &amp; eukaryota) down to order (rhizobiales, burkholderiales etc.). It is always good to be as specific as you can to your organisms lineage. A more specific lineage will have more BUSCOs that a more generic one. Note: All datasets end with _odb10 which stands for OrthoDB version 10 (https://www.orthodb.org/). Looking through the choices (and using NCBI taxonomy) what lineage dataset would you use for the following genera? Psychrobacter (Taxonomy ID: 497) Iamia (Taxonomy ID: 467975) Phycisphaera (Taxonomy ID: 666508) Atribacter (Taxonomy ID: 2847777) For our E.coli we will choose the enterobacterales_odb10 as our lineage dataset. With that we can run BUSCO on our genome assembly. busco \\ -i redbean_assembly/ecoli.ctg.fa \\ -l enterobacterales_odb10 \\ -m geno \\ -o ecoli \\ --out_path busco/redbean Parameter choice -i : The input genome assembly in fasat format. -l : The lineage dataset to be used. This has to end with the _odb10 part. This will download the dataset (if it does not exist) into a directory called busco_downloads in the current directory. The directory will be created if it doesn't exist. -m : The assessment mode. geno = genome assemblies (DNA) tran = transcriptome assemblies (DNA) prot = annotated gene sets (protein) -o : The run name. Output folders and files will be labelled with this name. --out_path : Path where the output directory will be created. There are many output files in the directory busco/redbean/ecoli. A full list of the output can be found in the following link: https://busco.ezlab.org/busco_userguide.html#outputs I ignore most of the output most of the time, instead only looking at the short summary file. less busco/redbean/ecoli/short_summary.specific.enterobacterales_obd10.ecoli.txt This provides us with 6 values. These values are presented in terms of percentage (along the top line of the Results) and total numbers (the next 6 lines). The values represent: Complete BUSCOs : The number of complete BUSCOs discovered. The closer this value is to 100% the better. This number is the sum of the next two values. Complete and single-copy BUSCOs: The number of BUSCOs found as complete and single-copy. The closer this number is to 100% the better. A good assembly will generally be &gt;90%. Complete and duplicated BUSCOs: Complete BUSCOs that have been found two or more times within the assembly. This indicates there are duplicated areas of the genome. Preferably we would like this number to be low. Fragmented BUSCOs: This could indicate that there are genes that are only partially present within the genome. This could be due to misassmebly. Missing BUSCOs: These are BUSCOs that could not be found in the genome assembly. This could indicate that parts of the genome are missing in the assembly. Total BUSCO groups searched: This represents the total number of BUSCOs within the lineage dataset used for analysis. For more info on interpreting the results please see the following link: https://busco.ezlab.org/busco_userguide.html#interpreting-the-results Questions Ignoring total BUSCOs, what is the highest value? Do you want this value to be the highest? Are these values good? What may the stats indicate? The BUSCO stats are ok. There are a bit more fragmented and missing BUSCOs than we would like. We'll try to improve this with polishing. We could also try to get some better data (maybe some Illumina data) or try a different assembler. However, as this is a workshop we will continue on. 6.4 CheckM CheckM can also be used to estimate the completeness of a bacterial genome, however I prefer BUSCO for this. Instead, we will use CheckM to estimate contamination within our assembly. First create an output directory. mkdir -p checkm/redbean/ecoli CheckM has many different commands. We will use its typical workflow which is conveniently wrapped into one command. Note: This command can take &gt;10 minutes. checkm lineage_wf \\ --tab_table \\ -f checkm/redbean/ecoli/ecoli_checkm.tsv \\ -t 8 \\ -x ctg.fa redbean_assembly/ \\ checkm/redbean/ecoli Parameters --tab_table : Creates a .tsv file (tab seperated value) that acts a summary of results. This is the one file we will inspect. -f : Path for output summary .tsv file. -t : Number of threads to be used. -x : Suffix of genome assembly files to be analysed. The command will carry out analysis on all the files with this suffix in the bin directory. The second last option (which is flagless) is the bin directory. The command will carry out the workflow on each file with the suffix as stated in the -x parameter. The last option (which is flagless) is the output directory. Ignore all the other files and view the summary files. less -S checkm/redbean/ecoli/ecoli_checkm.tsv There are quite a few statistics but we are only interested in the Contamination column (you may need to use the right key to move to it). This value is a percentage. Is it a large value? Thankfully not, it is less than 1%. If this was larger than 1% we may need to worry. If that was the case we could try to determine if it is real contamination and remove it if so. Please check out Blobtools2 if you ar einterested in contamination removal (link in Appendix) If you are interested in the other values please check: https://github.com/Ecogenomics/CheckM/wiki/Reported-Statistics 6.5 Assessment recap Our assembly looks good. Good contiguity figures from QUAST, and CheckM shows low signs, if any, contamination. The BUSCO values are not brilliant with some fragmented and missing BUSCOs. In real analysis I would try another assembler to see if that would improve the BUSCO situation. For the purpose of time we will continue and I will let you explore other assemblers in your own time. "],["07-Polishing.html", "Chapter 7 Polishing 7.1 Racon 7.2 Other polishers", " Chapter 7 Polishing Genome polishing is very important for long read assembly. This is due to the relatively high rate of error in PacBio and ONT technologies compared to Illumina. The general principle is to align reads to the genome assembly to correct incorrect bases. This is carried out by determining the consensus on each base. For example: The 10th base in a contig is A. Reads are aligned to the contig with 11 reads covering the 10th base. Therefore there are 11 bases form reads aligned to the 10th base. 4 of these bases are A, 1 is C, and 5 are Gs. In this case the polisher may determine that the 10th base is more likely to be a G and so polishes the base to a G. If possible I would recommend polishing with Illumina reads over long reads due to their accuracy if they are available. However, we only have PacBio reads so that is what we will use. 7.1 Racon Racon is a polisher that can use Illumina, PacBio or ONT reads to polish genome assemblies. This makes it a lot more flexible that other polishers that can only use one or two types of sequencing technologies for polishing. 7.1.1 Racon: Conda environment &amp; directory We will use the bacterial_assembly conda environment for our Racon polishing. Either: Use your currently open bacterial_assembly terminal. If you need a new bacterial_assembly terminal see the bacterial assembly conda activation instructions Ensure you are in the correct directory and create a new output directory. cd ~/bacterial_assembly/standard_workflow mkdir -p racon/redbean/ecoli 7.1.2 Racon: Index assembly The first step is to bwa index the assembly we want polished. This will create various index files that start with redbean_assembly/ecoli.ctg.fa and end with different suffixes (.ann, .bwt, .mmi, etc). Without the index files the read alignment process would be much more difficult and therefore slower. Imagine trying to search for a topic in an encyclopaedia without an index or trying to search for a topic in Wikipedia without the search bar. You could probably do it but it would take a lot longer. #Index the assmebly bwa index redbean_assembly/ecoli.ctg.fa #List the index files ls redbean_assembly/ecoli.ctg.fa.* 7.1.3 Racon: Read alignment to assembly With our index files created we can align the reads we will use for polishing to the assembly to be polished. This may take &gt;10 minutes. bwa mem \\ -t 8 \\ -x pacbio \\ redbean_assembly/ecoli.ctg.fa \\ ecoli_reads/ecoli.fastq \\ &gt; racon/redbean/ecoli/ecoli_i1.sam Parameters -t : Number of threads. -x : Read type. This will change various parameters to suit the read technology better. pacbio : Pacbio reads. ont2d : Oxford Nanopore 2D-reads The second last parameter (redbean_assembly/ecoli.ctg.fa) indicates the indexed assembly the reads will be aligned to. The last parameter (ecoli_reads/ecoli.fastq) indicates the reads to be aligned. The command would output the alignment to your screen (i.e. the standard output) but instead we will redirect (&gt;) it to a new file (racon/redbean/ecoli/ecoli_i1.sam). This is a SAM file which contains the alignment information (SAM file specification: https://samtools.github.io/hts-specs/SAMv1.pdf). BAM files are the binary version of SAM files. FOr most processes we would convert the SAM to BAM for storage purposes (BAM files are smaller than SAM files). However, Racon rquires a SAM file so we will not convert it to BAM. 7.1.4 Racon: Polishing Now that we have all the required files we will carry out Racon polishing. racon -t 8 \\ ecoli_reads/ecoli.fastq \\ racon/redbean/ecoli/ecoli_i1.sam \\ redbean_assembly/ecoli.ctg.fa \\ &gt; racon/redbean/ecoli/ecoli_i1.fasta Parameters -t : Number of threads. The first flagless input is the reads to be aligned. The second flagless input is the alignment file (SAM file). The third flagless input is the assembly to be polished. The output is redirected (&gt;) to a fasta file (racon/redbean/ecoli/ecoli_i1.fasta). This contains the polished assembly. 7.1.5 Racon: Polishing report unfortunately Racon does not create a polishing report. We will therefore create our own to determine how much polishing was carried out. This can be carried out with the dnadiff command from the program MUMmer. dnadiff will create quite a few files so we will create an output directory for its results. mkdir racon/redbean/ecoli/dnadiff We will use dnadiff to align the original assembly (reference) to our polished assembly (query). This will then provide detailed information on the differences between the two assemblies (i.e. we can see how polishing affected the assembly). dnadiff \\ --prefix racon/redbean/ecoli/dnadiff/ref_redbean_query_raconi1 \\ redbean_assembly/ecoli.ctg.fa \\ racon/redbean/ecoli/ecoli_i1.fasta Parameters --prefix : Prefix of the output files. The output files will be in the directory racon/redbean/ecoli/dnadiff/ with the prefix ref_redbean_query_raconi1. The first flagless input is the reference assembly for comparison. The second flagless input is the query assembly for comparison. List all the output files. There is a lot of information in them but for our purposes we will only inspect the report file. #List the output files ls racon/redbean/ecoli/dnadiff #View the report less -S racon/redbean/ecoli/dnadiff/ref_redbean_query_raconi1.report There is a lot of useful information in this file. The [REF] column represents the original assembly whilst the [QRY] column represent the polished assembly. Let us go through some (not all) of the stats. Note: Your values may differ from those mentioned below. [Sequences] TotalSeqs: We can see that we have dropped from 4 contigs to 1 contig. Racon has removed unpolished contigs. AlignedSeqs: Additionally, The 4 contigs of the reference align to the 1 contig of the query and vice versa. [Bases] TotalBases: Our total bases has decreased (~50k) from reference to query. [Feature Estimates] Insertions: There are 19 insertion events that consists of ~50Kbp in the reference assembly. This indicates these areas were caused by misassembly and removed from the query by polishing. [SNPs] TotalSNPs: We can see there are 627 SNPs between the two assemblies. This shows 627 were changed due to the polisher. TotalIndels: 3782 single nucleotide Indels were found. This indicates a lot of bases added and removed by polishing. The first four rows in the [QRY] column show added bases. ~2500 bases were added by polishing. The next four rows in the [QRY] column show bases removed by polishing. ~1200 bases were removed by polishing. This shows that polishing definetly worked and did quite a lot. For more info on dnadiff and the report statistics README: https://github.com/mummer4/mummer/blob/master/docs/dnadiff.README 7.1.6 Racon: Second iteration With genome polishing normally multiple iterations are required. Therefore let us polish the polished assembly to create the second iteration of polishing. #Index iteration 1 polished assembly bwa index racon/redbean/ecoli/ecoli_i1.fasta #Align the reads to iteration 1 polished assembly #This will create the second iteration SAM file bwa mem \\ -t 8 \\ -x pacbio \\ racon/redbean/ecoli/ecoli_i1.fasta \\ ecoli_reads/ecoli.fastq \\ &gt; racon/redbean/ecoli/ecoli_i2.sam #Polish iteration 1 pished assembly # Carried out with the second iteration SAM file racon \\ -t 8 \\ ecoli_reads/ecoli.fastq \\ racon/redbean/ecoli/ecoli_i2.sam \\ racon/redbean/ecoli/ecoli_i1.fasta \\ &gt; racon/redbean/ecoli/ecoli_i2.fasta With the second iteration of polishing carried out we will assess how much polishing was carried out with dnadiff. In this case we will use the first iteration polished assembly as the reference and the second iteration polished assembly as the query. dnadiff \\ --prefix racon/redbean/ecoli/dnadiff/ref_raconi1_query_raconi2 \\ racon/redbean/ecoli/ecoli_i1.fasta \\ racon/redbean/ecoli/ecoli_i2.fasta Inspect the new report file. less -S racon/redbean/ecoli/dnadiff/ref_raconi1_query_raconi2.report Questions Has the number of changes reduced? Would you carry out further polishing? The number of changes has indeed reduced by quite a bit, from 3782 to 40 TotalSNPs. When we are polishing we are looking for these stats to stop changing and converge to a similar value. Unfortunately my experience is that no matter how many iterations you carry out these stats will not go to zero. Instead the polisher gets to a certain point where it cannot tell what base certain positions should be. As an example one position could be polished to change it from an A to a G then in the next polishing iteration it will change from G to A and so on. So it would be advised to do some more polishing but for the sake of time we will continue on. 7.2 Other polishers Other polishers to explore for yourself include (links in appendix): Pilon PacBio's GenomicConsensus ONT's Medaka HyPo NextPolish "],["08-Circlator.html", "Chapter 8 Circularisation 8.1 Circlator", " Chapter 8 Circularisation Circularisation is useful for bacterial genomes which consist of circular chromosomes and plasmids. 8.1 Circlator Circlator, the first circularisation tool created, attempts to identify circular sequences and produce a linearised version of them. The goal is to have each circular sequence (chromosome or plasmid) as one contig with no overlap between the start and end of the contig. This would lead to a contig where if you moved one position forward/right from the last base in the contig you would wrap back around to the first base of the contig. 8.1.1 Circlator: Conda environment &amp; directory We will use the circlator conda environment for our Circlator circularisation. Open a new terminal (right click on the main screen, choose Applications -&gt; Shell -&gt; bash) and run: chos 8 . usecirclator Move to the standard_workflow directory and make a new output directory for Circlator. #Change directory cd ~/bacterial_assembly/standard_workflow #Make directory mkdir -p circlator/redbean_racon_i2/ 8.1.2 Circlator: Read correction Circlator requires corrected reads (reads with improved accuracy). There are various tools to correct reads (https://github.com/sanger-pathogens/circlator/wiki/Input-files-for-circlator). We will use the assembler Canu to correct our reads. If you assemble your data with Canu you would already have the corrected reads. Since we have not we can correct them now using the correction part and skipping the assembly part. Note: The below command takes a long time. In the interest of time skip the command and use the lower down copy command to get the pre-computed corrected reads. canu -correct \\ -p ecoli \\ -d ecoli_reads \\ genomeSize=4.6m \\ -pacbio ecoli_reads/ecoli.fastq Parameters -p : Prefix of output files. -d : Output directory. genomeSize= : Approximate genome size. -pacbio : Specify the pacbio reads to be used. Alternative options are: -nanopore and -pacbio-hifi. The above command would produce various files. However, we are only interested in the corrected reads. Copy the pre-computed corrected reads, these come in a .fasta.gz file, and gunzip the file for further use. #Copy corrected read fasta.gz file cp /pub39/tea/nsc006/NEOF/bact_assembly/data/ecoli.correctedReads.fasta.gz ecoli_reads #Gunzip file gunzip ecoli_reads/ecoli.correctedReads.fasta.gz 8.1.3 Circlator: Circularisation With the corrected reads we can now carry out the Circlator step. Circlator has many different commands for the various stages of circularisation: Check the input assembly: Formatting fasta headers. Map reads to assembly: Alignment of reads to the assmebly by BWA mem. Extract reads for reassembly: Extract the aligned reads, therefore removing reads that did not align to the assembly. Assembly of extracted reads: Carried out with the SPAdes assembler. Merge and circularise: Merges overlapping contigs from the assembly. Once merging is complete circular sequences are identified. Circular sequences are arranged so the last base is followed by the first base. Clean contigs: Removal of small contigs (default = 2k) and contigs completely contained in another contig. Fix contig start positions: Attempts to make the start position to be at a dnaA gene (if found). dnaA gene produces the \"Chromosomal replication initiator protein DnaA\" (https://www.uniprot.org/uniprot/P03004). To run all 7 steps as a workflow We will use the circlator all command (https://github.com/sanger-pathogens/circlator/wiki/Task:-all). circlator all \\ racon/redbean/ecoli/ecoli_i2.fasta \\ ecoli_reads/ecoli.correctedReads.fasta \\ circlator/redbean_racon_i2/ecoli Parameters The 1st flagless option is the input assembly to be circularised. The 2nd flagless option is the corrected reads to be used for circularisation, The 3rd flagless option is the output directory. You can list all the output noting the prefix number shows which step the files/directories were created at. ls circlator/redbean_racon_i2/ecoli The final circularised genome is in the file 06.fixstart.fasta. 8.1.4 Circlator: Assessment &amp; Polishing Now would be a good time to carry out a genome assessment to determine if circularisation was beneficial. Then it would be good to carry out further polishing. You are more than welcome to do that now, if not we will go onto annotation. "],["09-Annotation.html", "Chapter 9 Annotation 9.1 Prokka 9.2 Exploring annotations", " Chapter 9 Annotation Genome annotation is the act of identifying genomics features and adding useful information to these annotations. This includes adding information on genes, repeat regions, pathways etc.. 9.1 Prokka Prokka is a rapid genome annotation tool for bacterial, archaeal, and viral genomes. It is the standard method for bacterial genome annotation and wraps various other tools to carry out its processes. Prokka is fast, reliable and basic. It will detect genomic features such as CDS (coding sequence), genes, rRNA, and repeat regions. Additionally, it will provide pathway information for CDS annotations in the form of: EC (Enzyme Commission) numbers: This is a scheme of numbers grouping enzymes based on the reaction they catalyse. An example EC number is EC 3.1.1. The number are hierarchical. EC 3 = Hydrolase enzymes. EC 3.1 = Hydrolase enzymes that act on ester bonds. EC 3.1.1 = Carboxylic Ester Hydrolases. More info : https://en.wikipedia.org/wiki/Enzyme_Commission_number COG: Cluster of Orthologous Genes. Orthologs are gene sequences derived from the same ancestral gene present in two species' last common ancestor. COGs group CDS into three main tiers. COG Categories: This is the highest level grouping and are represented by the alphabet. Examples include: K - Transcription Z - Cytoskeleton L - Replication, Recombination, and Repair Pathways: The step below categories there are 63 different pathways represented in COG. Each pathway represnts different number of COGs. Examples of COG pathways include 16S rRNA modifciation (15 COGs), Arginine biosynthesis (12 COGs), and Glycolysis (18 COGs). List of COG pathways: https://www.ncbi.nlm.nih.gov/research/cog/pathways/ COGs: These are the clusters of Orthologous Genes. COGs are represented by a number, a symbol, and a name. Examples of COGs and their hierarchical classifications COG category Pathway COG number COG symbol Name J - Translation, Ribosomal Structure, and Biogenesis 16S rRNA modification COG0742 RsmD 16S rRNA G966 N2-methylase RsmD K - Transcription &amp; E - Amino Acid Transport &amp; Metabolism Lysine biosynthesis COG1167 ARO8 DNA-binding transcriptional regulator, MocR family, contains an aminotransferase domain H - Coenzyme transport and Metabolism Folate biosynthesis COG0302 FolE GTP cyclohydrolase I 9.1.1 Prokka: Conda environment &amp; directory Open a new terminal (right click on the main screen, choose Applications -&gt; Shell -&gt; bash). We will use the prokka conda environment for our genome annotation. chos 8 . useprokka Ensure you are in the standard workflow directory. cd ~/bacterial_assembly/standard_workflow Whenever I have my final genome assemblies I like to put them into a final directory that will contain all the output for them. Create a final directory and move into it. mkdir final_assembly cd final_assembly For ease I also like to make a directory that contains all the final assemblies. Additionally, it allows us to name the fasta files with the sample name. #Make directory mkdir assembly #Copy final assembly naming it with the sample name (ecoli) cp ../circlator/redbean_racon_i2/ecoli/06.fixstart.fasta assembly/ecoli.fasta 9.1.2 Prokka: Run Now it is time to run Prokka annotation #Make a prokka directory mkdir prokka #Run Prokka #outdir must not exist prokka \\ --addgenes \\ --prefix ecoli \\ --genus Escherichia \\ --species coli \\ --kingdom Bacteria \\ --outdir prokka/ecoli \\ assembly/ecoli.fasta Parameters --addgenes : This will add gene features for each CDS feature. --prefix : The prefix of the output files. --genus : The genus name that will be included in output. --species : The species name that will be included in output. --kingdom : Annotation mode to be used. Options are: Bacteria (default) Archaea Mitochondria Viruses --outdir : The output directory of Prokka. This must not exist before running the command. The last flagless parameter is the fasta file to be annotated. 9.1.3 Prokka: Output There are a lot of output files in the output directory. Below is a table with information on all these files. From: https://github.com/tseemann/prokka Extension Description .gff This is the master annotation in GFF3 format, containing both sequences and annotations. It can be viewed directly in Artemis or IGV. .gbk This is a standard Genbank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-Genbank, with one record for each sequence. .fna Nucleotide FASTA file of the input contig sequences. .faa Protein FASTA file of the translated CDS sequences. .ffn Nucleotide FASTA file of all the prediction transcripts (CDS, rRNA, tRNA, tmRNA, misc_RNA) .sqn An ASN1 format \"Sequin\" file for submission to Genbank. It needs to be edited to set the correct taxonomy, authors, related publication etc. .fsa Nucleotide FASTA file of the input contig sequences, used by \"tbl2asn\" to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines. .tbl Feature Table file, used by \"tbl2asn\" to create the .sqn file. .err Unacceptable annotations - the NCBI discrepancy report. .log Contains all the output that Prokka produced during its run. This is a record of what settings you used, even if the --quiet option was enabled. .txt Statistics relating to the annotated features found. .tsv Tab-separated file of all features: locus_tag,ftype,len_bp,gene,EC_number,COG,product The first file to look at is the summary .txt file. less -S prokka/ecoli/ecoli.txt Questions How many CDS are annotated? How many repeat regions were detected? The next best human-readable file is the .tsv file. This is in essence a table with one row per annotated feature. less -S prokka/ecoli/ecoli.tsv Questions What type of feature (ftype) is the first annotated feature? Which have more information tied to them, CDS or gene features? How many CDS features have been annotated as \"kefF\"? (Tip: The grep command is useful) What is the COG name for COG1662? We have our final assembly and our annotation now. In the next step we wll create a final report. 9.2 Exploring annotations There are various ways to inspect the annotation data. We will not go into them here, instead just introducing you to some tools and databases. Links to the tools are in the Manuals section of the appendix. IGV Artemis GhostKoala MinPath "],["10-Final_report.html", "Chapter 10 Final report 10.1 Report 10.2 Final recap", " Chapter 10 Final report 10.1 Report Once you have your final assmeblies it is always a good idea to make a final report. This will involve running QUAST and BUSCO on the final assemblies. Additionally, we will use MultiQC to make a html report including the metrics/stats from QUAST, BUSCO, and Prokka. 10.1.1 Report: Conda environment &amp; directory We will use the bacterial_genome_assessment conda environment for our report generation. Either: Use your currently open bacterial_genome_assessment terminal. If you need a new bacterial_genome_assessment terminal see the assembly assessment conda activation instructions Ensure you are in the final_assembly directory cd ~/bacterial_assembly/standard_workflow/final_assembly 10.1.2 Report: QUAST We will run QUAST but this time we will include a reference. Make a softlink for the genome reference. This reference genome is the genome used to create the PacBio simulated reads we have been using for assembly. ln -s /pub39/tea/nsc006/NEOF/bact_assembly/ref/ ~/bacterial_assembly/ Now we will run QUAST with the added option of -r specifying the reference fasta to be used. #Make QUAST output directory mkdir quast #Run QUAST quast -r ../../ref/ecoli_ref.fasta -o quast assembly/ecoli.fasta This -r option will add comparison metrics of the provided assembly/assemblies to the reference assembly. This is similar to dnadiff but more basic. We will look at the `QUAST metrics further down. 10.1.3 Report: BUSCO Now to run BUSCO for the assembly. #Make BUSCO directory mkdir busco #run BUSCO busco -i assembly/ecoli.fasta -l enterobacterales_odb10 -m geno -o ecoli --out_path ./busco/ 10.1.4 Report: MultiQC MultiQC will create a html report from the output from various tools. A list of compatible tools and output files can be found at: https://multiqc.info/docs/#multiqc-modules When running MultiQC the user points it to a directory or multiple directories which contain the output you want included in the report. MultiQC will then search through the files looking for all the compatible files and ignoring the incompatible files. However, I find MultiQC is very slow to search through files, especially for tools that create a lot of output files. I therefore like to create an input directory where I copy all the input for MultiQC so it will run much quicker. Let's do that now. #Make MultiQC directory mkdir multiqc #Move into MultiQC directory cd multiqc #Make a input directory mkdir input #Copy the relevant QUAST, BUSCO, and Prokka files to be used as MultiQC input cp ../quast/report.tsv input/ cp ../busco/ecoli/short_summary.specific.enterobacterales_odb10.txt input/ cp ../prokka/ecoli/ecoli.txt input/ Now we can run MultiQC. multiqc --cl-config &quot;prokka_fn_snames: True&quot; -o . input/ Parameters --cl-config : This parameter allows you to config how MultiQC will analyse/present data. \"prokka_fn_snames: True\": MultiQC will use the file names as the sample names. Other wise the sample name is generated using the first line of the Prokka .txt file. More info on configuring MultiQC: https://multiqc.info/docs/#configuring-multiqc -o : Output directory. At the end of the command all the input directories (directories with the MultiQC inputs) are supplied. In this case it is just input/ as it contains all our input. Inspect the html report. firefox multiqc_report.html In the QUAST Assembly Statistics table you will see normal contiguity metrics plus new metrics based on comparing the assembly to the reference assembly: Misassemblies: Number of misassmebly positions in contigs. Mismatches/100kbp: Average number of mismatches per 100000 aligned bases. Indels/100kbp: Average number of indels per 100000 aligned bases. Genome Fraction: Percentage of bases in the reference that aligned to the genome assembly. More info on metrics: http://quast.sourceforge.net/docs/manual.html#sec3.1 Questions What percentage of reference bases aligned to the genome assembly? When compared to the reference is there a higher number of Mismatches or Indels? Do you think Illumina sequencing would cause the same issue? How have the BUSCO metrics changed from the BUSCO of the original assembly? 10.2 Final recap We have produced a circularised, and polished genome assembly. Additionally we have annotated this assembly and assessed it for contiguity and completeness. The assembly has very good contiguity but not the highest completeness estimation which appears to be due to missassemblies from mismatches but primarily indels (as evidenced by comparing the assembly to the reference). Below are a few suggestions for how this could be improved in a real project: Better QC of the initial data. Filter out small reads (&lt;500-1kbp). Correct reads prior to the first assembly. Try out other long read assemblers. Further polishing Polishing after circularisation. Try out a different polisher. Include Illumina reads Hybrid assembly with PacBio and Illumina reads Polish PacBio reads with Illumina reads Polish the assembly with the Illumina reads rather than the PacBio reads. PacBio &amp; ONT reads are less accurate and more susceptible to indel errors than Illumina reads. As you can see there are a lot of ways to try to improve an assembly. That is why it is always important to carry out regular assembly assessment to determine if you are taking the best route. Additionally, it is also good to know if you have reached the optimum assembly from your data, if so there is not much point spending a lot more bioinformatics time to improve the assembly. Some times you need better/more data. "],["11-Cleanup.html", "Chapter 11 Cleanup 11.1 Deleting unwanted data 11.2 Compressing the final directory", " Chapter 11 Cleanup When carrying out a bioinformatics project it is always good to remove intermediary files that are not needed. We could delete all the directories apart from the final_assembly directory but instead we will delete files that are definitely not needed. This will leave files that we may want to use again (assembly fasta files, stats etc.). You can delete files/directories you definitely don't need as you go along (recommended for large files/directories or if storage space is a premium) but I tend to do my cleanup at the end of a project. 11.1 Deleting unwanted data Instead of running you through this by the normal conversational prose, I will instead give you the below code block with annotations to run through. Note: No specific conda environment is needed for this as we are using default linux commands. #Ensure you are in the standard_workflow directory cd ~/bacterial_assembly/standard_workflow #Use the du command to see the size of directories #This is useful to target larger files #Use `man du` if you are interested in know more about du and its options du -hsc * ##Redbean #Check file storage of redbean output du -hsc redbean_assembly/* #Delete the gzipped files that we will most likely never even look at #I always like to ls before using wildcards to delete or # when deleting directories #This helps ensure you are not going to delete anything you dont want to #rm -i is also a good way to not delete stuff by accident #It will give you a prompt before every removal ls redbean_assembly/*gz rm redbean_assembly/*gz #Delete the assembly index files #We created these for racon polishing ls redbean_assembly/ecoli.ctg.fa.* rm redbean_assembly/ecoli.ctg.fa.* ##QUAST #Generally quast does not produce large files so we will ignore its output ##BUSCO #Check file storage du -hsc busco/redbean/* #Delete the the BUSCO downloads directory #This contained the lineage dataset information ls busco_downloads rm -r busco_downloads #Check file storage of ecoli BUSCO results du -hsc busco/redbean/ecoli/* #Remove the logs directory ls busco/redbean/ecoli/logs rm -r busco/redbean/ecoli/logs #Remove the prodigal output ls busco/redbean/ecoli/prodigal_output rm -r busco/redbean/ecoli/prodigal_output #Remove the run output #This directory may be useful but normally the short summary # is sufficient to keep and use ls busco/redbean/ecoli/run_enterobacterales_odb10 rm -r busco/redbean/ecoli/run_enterobacterales_odb10 ## checkm #Check file storage du -hsc checkm/redbean/ecoli/* #Remove the CheckM storage directory ls checkm/redbean/ecoli/storage rm -r checkm/redbean/ecoli/storage ## racon #Check file storage du -hsc racon/redbean/ecoli/* #Delete the SAM files #These are relatively large and can be generated quickly ls racon/redbean/ecoli/*sam rm racon/redbean/ecoli/*sam #Remove the index files ls racon/redbean/ecoli/*.fasta.* rm racon/redbean/ecoli/*.fasta.* #The dnadiff output is small so we will leave it alone ##Circlator #Check file storage du -hsc circlator/redbean_raconi2/ecoli/* #We are only interested in the files produced by the 6th step #Delete all the 00-05 files ls circlator/redbean_raconi2/ecoli/0[0-5]* rm -r circlator/redbean_raconi2/ecoli/0[0-5]* ##Prokka #All the prokka files are useful so no deleting here Task Using the experience above cleanup unwanted files and directories in your final assembly directory 11.2 Compressing the final directory It is good practice to compress a cleaned directory when it is not needed any more. Lots of files will slow down a cluster whilst a compressed directory will only count as one file. Therefore if you like your analyses to run quickly please compress your project directories that you don't plan to touch again for more than 6 months. For practice you will make a copy of your bacterial_assembly directory. #Ensure in you ar ein correct directory cd ~/bacterial_assembly #Copy the standard_workflow directory with a new name cp -r standard_workflow standard_workflow_backup Now compress the directory standard_workflow_backup into the compressed archive standard_workflow.tar.gz. tar -czvf standard_workflow.tar.gz standard_workflow_backup Paramters -czvf : Consists of multiple flags. c : Create a new archive. In this case standard_workflow.tar.gz. z : After tar compression (.tar) carry out gzip compression (.gz). v : Verbosely lists files processed. f : Use archive file. This will mean that after unarchiving the directory will retain its original name. Now that we have a compressed version of the directory we will remove the directory. rm -rf standard_workflow_backup To uncompress the directory archive we use tar again but instead we use -x (uncompress) instead of -c (compress). #Uncompress tar -xzvf standard_workflow.tar.gz #List contents of uncompressed directory ls standard_workflow_backup Great! That is the end of this bookdown. Check out the appendix for some links to next steps and the websites of all the tools used in this workflow. "],["12-Appendix.html", "A Next steps B Manuals C Obtaining Read Data", " A Next steps Conda and Mamba are invaluable tools to install programs and create virtual environments. Assembly algorithms for next-generation sequencing data https://www.sciencedirect.com/science/article/pii/S0888754310000492 The Most Frequently Used Sequencing Technologies and Assembly Methods in Different Time Segments of the Bacterial Surveillance and RefSeq Genome Databases. https://www.frontiersin.org/articles/10.3389/fcimb.2020.527102/full Benchmarks of long-read assemblers paper. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6966772/ Predicting metabolic pathways using MinPath https://metagenomics-workshop.readthedocs.io/en/2014-11-uppsala/functional-annotation/minpath.html B Manuals Conda: https://conda.io/projects/conda/en/latest/user-guide/getting-started.html Mamba: https://github.com/mamba-org/mamba Redbean (wtdbg2): https://github.com/ruanjue/wtdbg2 Bandage: https://rrwick.github.io/Bandage/ GFA spec: http://gfa-spec.github.io/GFA-spec/GFA1.html Canu: https://github.com/marbl/canu HGAP: https://github.com/PacificBiosciences/Bioinformatics-Training/wiki/HGAP Flye: https://github.com/fenderglass/Flye Raven: https://github.com/lbcb-sci/raven NECAT: https://github.com/xiaochuanle/NECAT Shasta: https://github.com/chanzuckerberg/shasta QUAST: http://quast.sourceforge.net/quast BUSCO: https://busco.ezlab.org/ CheckM: https://github.com/Ecogenomics/CheckM/wiki BlobTools2: https://github.com/blobtoolkit/blobtools2 BWA: https://github.com/lh3/bwa SAM: https://samtools.github.io/hts-specs/SAMv1.pdf RACON: https://github.com/isovic/racon MUMmer: http://mummer.sourceforge.net/ dnadiff: https://github.com/mummer4/mummer/blob/master/docs/dnadiff.README Pilon: https://github.com/broadinstitute/pilon/wiki PacBio's GenomicConsensus: https://github.com/broadinstitute/pilon/wiki HyPo: https://github.com/kensung-lab/hypo Medaka: https://github.com/nanoporetech/medaka NextPolish: https://github.com/Nextomics/NextPolish Canu: https://github.com/marbl/canu Circlator: https://github.com/sanger-pathogens/circlator Prokka: https://github.com/tseemann/prokka EC numers: https://en.wikipedia.org/wiki/Enzyme_Commission_number COG: https://www.ncbi.nlm.nih.gov/research/cog IGV: https://software.broadinstitute.org/software/igv/v1.2 Artemis: http://sanger-pathogens.github.io/Artemis/Artemis/ GhostKOALA: https://www.kegg.jp/ghostkoala/ MinPath: https://github.com/mgtools/MinPath C Obtaining Read Data https://github.com/PacificBiosciences/DevNet/wiki/8-plex-Ecoli-Multiplexed-Microbial-Assembly "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
